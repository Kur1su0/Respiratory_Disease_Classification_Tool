{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respiratory Disease Classification\n",
    "\n",
    "Authors: Zice Wei, Ben Shealy\n",
    "\n",
    "In this notebook we demonstrate how to classify respiratory diseases using the [Respiratory Sound Database](https://www.kaggle.com/vbookshelf/respiratory-sound-database) from Kaggle. This dataset contains audio samples of people coughing, and each sample is annotated with the individual's respiratory disease and other metadata such as age, gender, height, and weight.\n",
    "\n",
    "To perform the classification, we will create a hybrid neural network model which has a CNN branch to process the audio data and an MLP branch to process the metadata. The features from the two branches are concatenated and followed by some dense layers to form the full network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import concatenate, Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D, Input, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Metadata\n",
    "\n",
    "The disease labels and metadata are in two separate files so we will load them and combine them into one dataframe. Additionally, many of the samples are missing height or weight or BMI, and since BMI is computed from height and weight we will simply compute BMI for each sample and then discard height and weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read labels and metadata\n",
    "df_labels = pd.read_csv(\n",
    "    'Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv',\n",
    "    names=['Patient No', 'Disease']\n",
    ")\n",
    "df_metadata = pd.read_csv(\n",
    "    'demographic_info.txt',\n",
    "    sep=' ',\n",
    "    names=['Patient No', 'Age', 'Gender', 'BMI for Adults', 'Weight (Children)', 'Height (Children)']\n",
    ")\n",
    "\n",
    "# append labels to metadata\n",
    "df_metadata['Disease'] = df_labels['Disease']\n",
    "\n",
    "# compute BMI for all samples\n",
    "df_metadata['BMI for Children'] = (df_metadata['Weight (Children)'] / (df_metadata['Height (Children)'] ** 2)) * 10000\n",
    "df_metadata['BMI'] = df_metadata['BMI for Adults'].combine_first(df_metadata['BMI for Children'])\n",
    "\n",
    "# remove unused columns\n",
    "df_metadata.drop(['Weight (Children)', 'Height (Children)', 'BMI for Adults', 'BMI for Children'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Audio Metadata\n",
    "\n",
    "For now we will simply get all of the audio filenames and append them to the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parent directory of audio files\n",
    "audio_path = 'Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/'\n",
    "\n",
    "# get filenames of audio (wav) files\n",
    "filenames = [f for f in os.listdir(audio_path) if (os.path.isfile(os.path.join(audio_path, f)) and f.endswith('.wav'))]\n",
    "\n",
    "# extract patient number from each filename\n",
    "patient_ids = [int(f.split('_')[0]) for f in filenames]\n",
    "\n",
    "# create dataframe of audio metadata\n",
    "df_audio = pd.DataFrame({\n",
    "    'Patient No': patient_ids,\n",
    "    'filename': filenames\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata.set_index('Patient No', inplace=True)\n",
    "df_audio.set_index('Patient No', inplace=True)\n",
    "\n",
    "df_metadata = df_metadata.join(df_audio, on='Patient No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Missing Samples\n",
    "\n",
    "Even after filling in the missing BMI values, after appending the audio filenames we see that there are still some samples that are missing several metadata fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_metadata.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these samples have an audio file but no metadata, so we must simply discard those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata.dropna(thresh=3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_metadata.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the only remaining problem is samples without a BMI value. To handle these cases we will attempt to interpolate the BMI value from similar samples. If we cannot find enough similar samples then we will simply discard the incomplete sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = df_metadata[df_metadata['BMI'].isnull()].index\n",
    "\n",
    "for index in indices:\n",
    "    row = df_metadata.iloc[index]\n",
    "\n",
    "    # attempt to find similar samples by gender, disease, and age\n",
    "    similar_samples = df_metadata[\n",
    "        (df_metadata['Gender'] == row['Gender'])\n",
    "        & (df_metadata['Disease'] == row['Disease'])\n",
    "        & (row['Age'] - 5 <= df_metadata['Age'])\n",
    "        & (df_metadata['Age'] <= row['Age'] + 5)\n",
    "        & ~df_metadata['BMI'].isnull()\n",
    "    ]\n",
    "\n",
    "    # estimate missing BMI value if at least 3 similar samples are found\n",
    "    if len(similar_samples.index) >= 3:\n",
    "        df_metadata.at[index, 'BMI'] = similar_samples['BMI'].mean()\n",
    "\n",
    "    # otherwise discard the sample\n",
    "    else:\n",
    "        df_metadata.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Metadata\n",
    "\n",
    "We have loaded the metadata and filtered out samples with missing values, which means we now have the samples that we will use in our classification models. Now let's take a moment to visualize some properties of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_metadata['Age'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Gender', data=df_metadata)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_metadata['BMI'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(y='Disease', data=df_metadata)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Audio Data\n",
    "\n",
    "Now let's take a break from the metadata for a moment and load the audio data. An audio sample is a time series, but we will use the MFCC of each audio sample instead of the raw audio. The MFCC is essentially a frequency spectrum that can be viewed as an image; each column in the image is the spectrum for a single time point and each row represents a particular frequency range. Since the MFCC for an audio sample is like an image, ultimately we will use a CNN to learn the MFCC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_width = 862\n",
    "\n",
    "X_mfcc = []\n",
    "filenames = [os.path.join(audio_path, f) for f in df_metadata['filename']]\n",
    "\n",
    "for filename in filenames:\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(filename, res_type='kaiser_fast', duration=20) \n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_width - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", filename)\n",
    "        mfcc = np.nan\n",
    "\n",
    "    X_mfcc.append(mfcc)\n",
    "\n",
    "X_mfcc = np.array(X_mfcc).reshape(X_mfcc.shape[0], X_mfcc.shape[1], X_mfcc.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Audio Data\n",
    "\n",
    "We'll write a function to plot the audio signal and corresponding MFCC spectrum of a given sample so that we can see what the MFCC looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wav_mfcc(index):\n",
    "    row = df_metadata.iloc[index]\n",
    "    filename = filenames[index]\n",
    "    mfcc = X_mfcc[index]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    y, sr = librosa.load(filename, duration=20)\n",
    "    librosa.display.waveplot(y, sr=sr)\n",
    "    plt.title('Patient No = %s, Disease = %s' % (row.name, row['Disease']))\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    librosa.display.specshow(mfcc, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wav_mfcc(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training\n",
    "\n",
    "Now there are a few more preprocessing steps that need to be done before we can starting training our models with our dataset. The categorical features (gender, disease) need to be converted into numerical codes. The numerical features (age, BMI) need to be normalized to have roughly the same scale, but we need to split the dataset into train/test sets first so that we normalize the data based on the training set alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract input features from metadata\n",
    "X_meta = df_metadata[[\"Age\", \"Gender\", \"BMI\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert gender to categorical feature\n",
    "X_meta['Gender'] = X_meta['Gender'].map({'F': 0, 'M': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert disease label to a one-hot encoding\n",
    "y, class_names = pd.factorize(df_metadata['Disease'])\n",
    "y = keras.utils.to_categorical(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test sets for both metadata and mfcc data\n",
    "X_meta_train, X_meta_test, X_mfcc_train, X_mfcc_test, y_train, y_test = train_test_split(X_meta, X_mfcc, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the numerical features to have the same scale\n",
    "columns = ['Age', 'BMI']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_meta_train[columns])\n",
    "X_meta_train.loc[:, columns] = scaler.transform(X_meta_train[columns])\n",
    "X_meta_test.loc[:, columns] = scaler.transform(X_meta_test[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Hybrid Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cnn branch (for mfcc data)\n",
    "n_rows = X_mfcc.shape[1]\n",
    "n_cols = X_mfcc.shape[2]\n",
    "n_channels = X_mfcc.shape[3]\n",
    "kernel_size = (2, 2)\n",
    "\n",
    "cnn_inputs = Input(shape=(n_rows, n_cols, n_channels))\n",
    "\n",
    "cnn_branch = Conv2D(filters=16, kernel_size=kernel_size, activation='relu')(cnn_inputs)\n",
    "cnn_branch = MaxPooling2D(pool_size=2)(cnn_branch)\n",
    "cnn_branch = Dropout(0.2)(cnn_branch)\n",
    "\n",
    "cnn_branch = Conv2D(filters=64, kernel_size=kernel_size, activation='relu')(cnn_branch)\n",
    "cnn_branch = MaxPooling2D(pool_size=2)(cnn_branch)\n",
    "cnn_branch = Dropout(0.2)(cnn_branch)\n",
    "\n",
    "cnn_branch = Flatten()(cnn_branch)\n",
    "\n",
    "# enable this code to create a stand-alone cnn model\n",
    "# n_classes = len(class_names)\n",
    "# cnn = GlobalAveragePooling2D()(cnn_branch)\n",
    "# cnn_outputs = Dense(n_classes, activation='softmax')(cnn)\n",
    "# cnn = Model(inputs=cnn_inputs, outputs=cnn_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mlp branch (for metadata)\n",
    "n_classes = len(class_names)\n",
    "\n",
    "mlp_inputs = Input(shape=(3,))\n",
    "mlp_branch = Dense(units=64, activation=\"relu\")(mlp_inputs)\n",
    "mlp_branch = Dense(units=64, activation=\"relu\")(mlp_branch)\n",
    "mlp_branch = Dense(units=64, activation=\"relu\")(mlp_branch)\n",
    "\n",
    "# enable this code to create a stand-alone mlp model\n",
    "# n_classes = len(class_names)\n",
    "# mlp_outputs = Dense(units=num_label, activation=\"softmax\")(mlp_branch)\n",
    "# mlp = Model(inputs=mlp_inputs, outputs=mlp_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hybrid neural network model\n",
    "n_classes = len(class_names)\n",
    "\n",
    "hnn = concatenate([cnn_branch, mlp_branch])\n",
    "hnn = Flatten()(hnn)\n",
    "hnn_outputs = Dense(units=n_classes, activation='sigmoid')(hnn)\n",
    "hnn = Model(inputs=[cnn_inputs, mlp_inputs], outputs=hnn_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnn.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an image of the hybrid model\n",
    "keras.utils.plot_model(hnn, to_file='hybrid_model.png')\n",
    "\n",
    "IPython.display.Image('hybrid_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history = hnn.fit(\n",
    "    [X_mfcc_train, X_meta_train],\n",
    "    y_train,\n",
    "    batch_size=8,\n",
    "    epochs=100,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training accuracy\n",
    "plt.plot(history.history[\"acc\"])\n",
    "plt.plot(history.history[\"val_acc\"])\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "    \n",
    "# plot the training loss\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Training Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Training\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "hnn.evaluate([X_mfcc_test, X_meta_test], y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (mlbd)",
   "language": "python",
   "name": "mlbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
